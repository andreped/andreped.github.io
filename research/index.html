<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>AndrÃ©  Pedersen | research</title>
    <meta name="author" content="AndrÃ©  Pedersen" />
    <meta name="description" content="selection of publications I have contributed to, either peer-reviewed or preprints." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="raw.githubusercontent.com/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 120 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§ </text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://andreped.dev/research/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://andreped.dev/"><span class="font-weight-bold">AndrÃ©</span>   Pedersen</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/demos/">demos</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">datasets</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="https://dataverse.no/dataset.xhtml?persistentId=doi:10.18710/TLA01U" target="_blank" rel="noopener noreferrer">IBDColEpi</a>
                  <a class="dropdown-item" href="https://github.com/raidionics/AeroPath" target="_blank" rel="noopener noreferrer">AeroPath</a>
                  <a class="dropdown-item" href="https://github.com/raidionics/LyNoS" target="_blank" rel="noopener noreferrer">LyNoS</a>
                </div>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/research/">research<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">software</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="https://github.com/AICAN-Research/FAST-Pathology" target="_blank" rel="noopener noreferrer">FastPathology</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/GradientAccumulator" target="_blank" rel="noopener noreferrer">GradientAccumulator</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/SINTEFMedtek/GSI-RADS" target="_blank" rel="noopener noreferrer">GSI-RADS</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/dbouget/Raidionics" target="_blank" rel="noopener noreferrer">Raidionics</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/livermask" target="_blank" rel="noopener noreferrer">livermask</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/VemundFredriksen/LungTumorMask" target="_blank" rel="noopener noreferrer">LungTumorMask</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/EIDOSlab/torchstain" target="_blank" rel="noopener noreferrer">torchstain</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/fast-stain-normalization" target="_blank" rel="noopener noreferrer">fast-stain-normalization</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/DSS" target="_blank" rel="noopener noreferrer">DSS</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/super-ml-pets" target="_blank" rel="noopener noreferrer">super-ml-pets</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="https://github.com/andreped/FP-DSA-plugin" target="_blank" rel="noopener noreferrer">FP-dsa-plugin</a>
                </div>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">research</h1>
            <p class="post-description">selection of publications I have contributed to, either peer-reviewed or preprints.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2025</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Fron.Med</abbr></div>

        <!-- Entry bib key -->
        <div id="hoibo2025estrogenreceptor" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Predicting estrogen receptor status from HE-stained breast cancer slides using artificial intelligence</div>
          <!-- Author -->
          <div class="author">Maren HÃ¸ibÃ¸,Â Ute Spiske,Â 
                  <em>AndrÃ© Pedersen</em>,Â Borgny Ytterhus,Â Lars A. Akslen,Â Elisabeth Wik,Â Cecilie Askeland,Â Ingerid Reinertsen,Â Erik Smistad,Â and Marit Valla
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Frontiers in Medicine</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1593143/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Introduction The estrogen receptor (ER) is routinely assessed by immunohistochemistry (IHC) in breast cancer to stratify patients into therapeutic and prognostic groups. Pathology laboratories are burdened by an increased number of biopsies, and costly and resource-demanding molecular pathology analyses. Automatic, artificial intelligence-based prediction of biological properties from hematoxylin and eosin (HE)-stained slides could increase efficiency and potentially reduce costs at laboratories. The aim of this study was to develop a model for prediction of ER status from HE-stained tissue microarrays (TMAs). Our methodology can be used as proof-of-concept for the prediction of more complex and costly molecular analyses in cancer. Methods In this study, TMAs from more than 2,000 Norwegian breast cancer patients were used to train and predict ER status using the clustering-constrained attention multiple-instance learning (CLAM) framework. Two patch sizes were evaluated, multi-branch and single-branch CLAM configurations were compared, and a comprehensive hyperparameter search with more than 16 000 experiments was performed. The models were evaluated on internal and external test sets. Results On the internal test set, the proposed model achieved a micro accuracy, a macro accuracy, and an area under the curve of 0.91, 0.86, and 0.95, respectively. The corresponding results on the external test set were 0.93, 0.76, and 0.91, respectively. Using larger patch sizes resulted in significantly better classification performance, while no significant differences were observed when changing CLAM configurations.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hoibo2025estrogenreceptor</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{HÃ¸ibÃ¸, Maren and Spiske, Ute and Pedersen, AndrÃ© and Ytterhus, Borgny and Akslen, Lars A. and Wik, Elisabeth and Askeland, Cecilie and Reinertsen, Ingerid and Smistad, Erik and Valla, Marit}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predicting estrogen receptor status from HE-stained breast cancer slides using artificial intelligence}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{Volume 12 - 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1593143}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fmed.2025.1593143}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2296-858X}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1593143/full}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Fron.Med}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">JNS</abbr></div>

        <!-- Entry bib key -->
        <div id="majewska2025prognosticavalue" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Prognostic value of manual versus automatic methods for assessing extents of resection and residual tumor volume in glioblastoma</div>
          <!-- Author -->
          <div class="author">Paulina Majewska,Â Ragnhild Holden Helland,Â Alexandros Ferles,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ivar Kommers,Â Hilko Ardon,Â Frederik Barkhof,Â Lorenzo Bello,Â Mitchel S. Berger,Â Tora DunÃ¥s,Â Marco Conti Nibali,Â Julia Furtner,Â Shawn L. Hervey-Jumper,Â Albert J. S. Idema,Â Barbara Kiesel,Â Rishi Nandoe Tewarie,Â Emmanuel Mandonnet,Â Domenique M. J. MÃ¼ller,Â Pierre A. Robe,Â Marco Rossi,Â Tommaso Sciortino,Â Tom Aalders,Â Michiel Wagemakers,Â Georg Widhalm,Â Aeilko H. Zwinderman,Â Philip C. De Witt Hamer,Â Roelant S. Eijgelaar,Â Lisa MillgÃ¥rd Sagberg,Â Asgeir Store Jakola,Â Erik Thurin,Â Ingerid Reinertsen,Â David Bouget,Â and Ole Solheim
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Neurosurgery</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.3171/2024.8.JNS24415" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>OBJECTIVE The extent of resection (EOR) and postoperative residual tumor (RT) volume are prognostic factors in glioblastoma. Calculations of EOR and RT rely on accurate tumor segmentations. Raidionics is an open-access software that enables automatic segmentation of preoperative and early postoperative glioblastoma using pretrained deep learning models. The aim of this study was to compare the prognostic value of manually versus automatically assessed volumetric measurements in glioblastoma patients. METHODS Adult patients who underwent resection of histopathologically confirmed glioblastoma were included from 12 different hospitals in Europe and North America. Patient characteristics and survival data were collected as part of local tumor registries or were retrieved from patient medical records. The prognostic value of manually and automatically assessed EOR and RT volume was compared using Cox regression models. RESULTS Both manually and automatically assessed RT volumes were a negative prognostic factor for overall survival (manual vs automatic: HR 1.051, 95% CI 1.034â€“1.067 [p &lt; 0.001] vs HR 1.019, 95% CI 1.007â€“1.030 [p = 0.001]). Both manual and automatic EOR models showed that patients with gross-total resection have significantly longer overall survival compared with those with subtotal resection (manual vs automatic: HR 1.580, 95% CI 1.291â€“1.932 [p &lt; 0.001] vs HR 1.395, 95% CI 1.160â€“1.679 [p &lt; 0.001]), but no significant prognostic difference of gross-total compared with near-total (90%â€“99%) resection was found. According to the Akaike information criterion and the Bayesian information criterion, all multivariable Cox regression models showed similar goodness-of-fit. CONCLUSIONS Automatically and manually measured EOR and RT volumes have comparable prognostic properties. Automatic segmentation with Raidionics can be used in future studies in patients with glioblastoma.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">majewska2025prognosticavalue</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{JNS}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Majewska, Paulina and Helland, Ragnhild Holden and Ferles, Alexandros and Pedersen, AndrÃ© and Kommers, Ivar and Ardon, Hilko and Barkhof, Frederik and Bello, Lorenzo and Berger, Mitchel S. and DunÃ¥s, Tora and Nibali, Marco Conti and Furtner, Julia and Hervey-Jumper, Shawn L. and Idema, Albert J. S. and Kiesel, Barbara and Tewarie, Rishi Nandoe and Mandonnet, Emmanuel and MÃ¼ller, Domenique M. J. and Robe, Pierre A. and Rossi, Marco and Sciortino, Tommaso and Aalders, Tom and Wagemakers, Michiel and Widhalm, Georg and Zwinderman, Aeilko H. and Hamer, Philip C. De Witt and Eijgelaar, Roelant S. and Sagberg, Lisa MillgÃ¥rd and Jakola, Asgeir Store and Thurin, Erik and Reinertsen, Ingerid and Bouget, David and Solheim, Ole}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Prognostic value of manual versus automatic methods for assessing extents of resection and residual tumor volume in glioblastoma}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Neurosurgery}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Association of Neurological Surgeons}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3171/2024.8.JNS24415}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1 - 9}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://thejns.org/view/journals/j-neurosurg/aop/article-10.3171-2024.8.JNS24415/article-10.3171-2024.8.JNS24415.xml}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3171/2024.8.JNS24415}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="oskouei2025drunet" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Segmentation of Non-Small Cell Lung Carcinomas: Introducing DRU-Net and Multi-Lens Distortion</div>
          <!-- Author -->
          <div class="author">Soroush Oskouei,Â Marit Valla,Â 
                  <em>AndrÃ© Pedersen</em>,Â Erik Smistad,Â Vibeke Grotnes Dale,Â Maren HÃ¸ibÃ¸,Â Sissel Gyrid Freim Wahl,Â Mats Dehli Haugum,Â Thomas LangÃ¸,Â Maria Paula Ramnefjell,Â Lars Andreas Akslen,Â Gabriel Kiss,Â and Hanne Sorger
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Imaging</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.mdpi.com/2313-433X/11/5/166" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/AICAN-Research/DRU-Net" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The increased workload in pathology laboratories today means automated tools such as artificial intelligence models can be useful, helping pathologists with their tasks. In this paper, we propose a segmentation model (DRU-Net) that can provide a delineation of human non-small cell lung carcinomas and an augmentation method that can improve classification results. The proposed model is a fused combination of truncated pre-trained DenseNet201 and ResNet101V2 as a patch-wise classifier, followed by a lightweight U-Net as a refinement model. Two datasets (Norwegian Lung Cancer Biobank and Haukeland University Lung Cancer cohort) were used to develop the model. The DRU-Net model achieved an average of 0.91 Dice similarity coefficient. The proposed spatial augmentation method (multi-lens distortion) improved the Dice similarity coefficient from 0.88 to 0.91. Our findings show that selecting image patches that specifically include regions of interest leads to better results for the patch-wise classifier compared to other sampling methods. A qualitative analysis by pathology experts showed that the DRU-Net model was generally successful in tumor detection. Results in the test set showed some areas of false-positive and false-negative segmentation in the periphery, particularly in tumors with inflammatory and reactive changes. In summary, the presented DRU-Net model demonstrated the best performance on the segmentation task, and the proposed augmentation technique proved to improve the results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">oskouei2025drunet</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Oskouei, Soroush and Valla, Marit and Pedersen, AndrÃ© and Smistad, Erik and Dale, Vibeke Grotnes and HÃ¸ibÃ¸, Maren and Wahl, Sissel Gyrid Freim and Haugum, Mats Dehli and LangÃ¸, Thomas and Ramnefjell, Maria Paula and Akslen, Lars Andreas and Kiss, Gabriel and Sorger, Hanne}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Segmentation of Non-Small Cell Lung Carcinomas: Introducing DRU-Net and Multi-Lens Distortion}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Imaging}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">article-number</span> <span class="p">=</span> <span class="s">{166}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2313-433X/11/5/166}</span><span class="p">,</span>
  <span class="na">pubmedid</span> <span class="p">=</span> <span class="s">{40423022}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2313-433X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/jimaging11050166}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/AICAN-Research/DRU-Net}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2313-433X/11/5/166}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">miccai</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2024agunetbrats2023" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">The AGU-Net Architecture forÂ Brain Tumor Segmentation: BraTS Challenges 2023</div>
          <!-- Author -->
          <div class="author">David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ole Solheim,Â and Ingerid Reinertsen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Brain Tumor Segmentation, and Cross-Modality Domain Adaptation for Medical Image Segmentation</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-031-76163-8_2" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>For patients suffering from brain tumors, prognosis estimation and treatment decisions are made by a multidisciplinary team of medical doctors based on a set of MR scans. Currently, the lack of automatic, standardized, and robust methods for tumor characterization represents a major hurdle for use in clinical practice. This paper describes our contribution to the BraTS 2023 Continuous Evaluation challenge for the segmentation of all tumor types, using our single-stage AGU-Net architecture and various training strategies. Performance over the training sets were reported using our custom pixel-wise, patient-wise, and lesion-wise metrics. For the tumor core, an average lesion-wise Dice score of 85% was obtained over the glioma challenges, 80% for the meningioma challenge, and 73% for the metastasis challenge. Performance reported over the validation and test sets were officially computed by the challenge team. Over the test sets, an average lesion-wise Dice score of 75% to 80% was achieved for the tumor core over the glioma and meningioma challenges, while a lower score of 43% was reached for the metastasis challenge. The proposed method performed well and showed an ability to generalize on challenges with sufficient data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bouget2024agunetbrats2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Pedersen, Andr{\'e} and Solheim, Ole and Reinertsen, Ingerid}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Baid, Ujjwal and Dorent, Reuben and Malec, Sylwia and Pytlarz, Monika and Su, Ruisheng and Wijethilake, Navodini and Bakas, Spyridon and Crimi, Alessandro}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{The AGU-Net Architecture forÂ Brain Tumor Segmentation: BraTS Challenges 2023}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Brain Tumor Segmentation, and Cross-Modality Domain Adaptation for Medical Image Segmentation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature Switzerland}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11--23}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-76163-8}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{miccai}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-031-76163-8_2}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-031-76163-8_2}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{23}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PLOS ONE</abbr></div>

        <!-- Entry bib key -->
        <div id="stÃ¸verud2024aeropath" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">AeroPath: An airway segmentation benchmark dataset with challenging pathology and baseline method</div>
          <!-- Author -->
          <div class="author">Karen-Helene StÃ¸verud,Â David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â HÃ¥kon Olav Leira,Â Tore Amundsen,Â Thomas LangÃ¸,Â and Erlend Fagertun Hofstad
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>PLOS ONE</em> Oct 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1371/journal.pone.0311416" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/raidionics/AeroPath" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>To improve the prognosis of patients suffering from pulmonary diseases, such as lung cancer, early diagnosis and treatment are crucial. The analysis of CT images is invaluable for diagnosis, whereas high quality segmentation of the airway tree are required for intervention planning and live guidance during bronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATMâ€™22) challenge released a large dataset, both enabling training of deep-learning based models and bringing substantial improvement of the state-of-the-art for the airway segmentation task. The ATMâ€™22 dataset includes a large group of COVIDâ€™19 patients and a range of other lung diseases, however, relatively few patients with severe pathologies affecting the airway tree anatomy was found. In this study, we introduce a new public benchmark dataset (AeroPath), consisting of 27 CT images from patients with pathologies ranging from emphysema to large tumors, with corresponding trachea and bronchi annotations. Second, we present a multiscale fusion design for automatic airway segmentation. Models were trained on the ATMâ€™22 dataset, tested on the AeroPath dataset, and further evaluated against competitive open-source methods. The same performance metrics as used in the ATMâ€™22 challenge were used to benchmark the different considered approaches. Lastly, an open web application is developed, to easily test the proposed model on new data. The results demonstrated that our proposed architecture predicted topologically correct segmentations for all the patients included in the AeroPath dataset. The proposed method is robust and able to handle various anomalies, down to at least the fifth airway generation. In addition, the AeroPath dataset, featuring patients with challenging pathologies, will contribute to development of new state-of-the-art methods. The AeroPath dataset and the web application are made openly available.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">stÃ¸verud2024aeropath</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AeroPath: An airway segmentation benchmark dataset with challenging pathology and baseline method}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{StÃ¸verud, Karen-Helene and Bouget, David and Pedersen, AndrÃ© and Leira, HÃ¥kon Olav and Amundsen, Tore and LangÃ¸, Thomas and Hofstad, Erlend Fagertun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Public Library of Science}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1371/journal.pone.0311416}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-18}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/raidionics/AeroPath}</span><span class="p">,</span>
  <span class="na">demo</span> <span class="p">=</span> <span class="s">{https://huggingface.co/spaces/andreped/AeroPath}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://zenodo.org/records/10069289}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1371/journal.pone.0311416}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Neu.Onc.Adv</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1093/noajnl/vdad157" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Growth dynamics of untreated meningiomas</div>
          <!-- Author -->
          <div class="author">Per Sveino Strand,Â Kathrine JÃ¸rgensen WÃ¥gÃ¸,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ingerid Reinertsen,Â Olivia NÃ¤lsund,Â Asgeir Store Jakola,Â David Bouget,Â Sayied Abdol Mohieb Hosainey,Â Lisa MillgÃ¥rd Sagberg,Â Johanna Vanel,Â and Ole Solheim
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Neuro-Oncology Advances</em> Jan 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1093/noajnl/vdad157" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/andreped/tumor-growth" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Knowledge about meningioma growth characteristics is needed for developing biologically rational follow-up routines. In this study of untreated meningiomas followed with repeated MRIs, we studied growth dynamics and explored potential factors associated with tumor growth.In a single-center cohort study, we included 235 adult patients with a radiologically suspected intracranial meningioma and at least three MRI scans during follow-up. Tumors were segmented using an automatic algorithm from contrast enhanced T1-series, and if needed manually corrected. Potential meningioma growth curves were statistically compared; linear, exponential, linear radial, or Gompertzian. Factors associated with growth were explored.In 235 patients, 1394 MRI scans were carried out in the median five-year observational period. Of the models tested, a Gompertzian growth curve best described growth dynamics of meningiomas on group level. 59 \% of the tumors grew, 27 \% remained stable, and 14 \% shrunk. Only 13 patients (5 \%) underwent surgery during the observational period and were excluded after surgery. Tumor size at time of diagnosis, multifocality, and length of follow-up were associated with tumor growth, whereas age, sex, presence of peritumoral edema or hyperintense T2-signal were not significant factors.Untreated meningiomas follow a Gompertzian growth curve, indicating that increasing and potentially doubling of subsequent follow-up intervals between MRIs seems biologically reasonable, instead of fixed time intervals. Tumor size at diagnosis is the strongest predictor of future growth, indicating a potential for longer follow up intervals for smaller tumors. Although most untreated meningiomas grow, few require surgery.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1093/noajnl/vdad157</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Neu.Onc.Adv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Strand, Per Sveino and WÃ¥gÃ¸, Kathrine JÃ¸rgensen and Pedersen, AndrÃ© and Reinertsen, Ingerid and NÃ¤lsund, Olivia and Jakola, Asgeir Store and Bouget, David and Hosainey, Sayied Abdol Mohieb and Sagberg, Lisa MillgÃ¥rd and Vanel, Johanna and Solheim, Ole}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Growth dynamics of untreated meningiomas}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neuro-Oncology Advances}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{vdad157}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2632-2498}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/noajnl/vdad157}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/noajnl/vdad157}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{https://academic.oup.com/noa/advance-article-pdf/doi/10.1093/noajnl/vdad157/54703996/vdad157.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/andreped/tumor-growth}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/noajnl/vdad157}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div>

        <!-- Entry bib key -->
        <div id="hoibo2023immunohistochemistry" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Immunohistochemistry guided segmentation of benign epithelial cells, in situ lesions, and invasive epithelial cells in breast cancer slides</div>
          <!-- Author -->
          <div class="author">Maren HÃ¸ibÃ¸,Â 
                  <em>AndrÃ© Pedersen</em>,Â Vibeke Grotnes Dale,Â Sissel Marie Berget,Â Borgny Ytterhus,Â Cecilia Lindskog,Â Elisabeth Wik,Â Lars A. Akslen,Â Ingerid Reinertsen,Â Erik Smistad,Â and Marit Valla
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>arXiv</em> Nov 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2311.13261" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/AICAN-Research/breast-epithelium-segmentation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Digital pathology enables automatic analysis of histopathological sections using artificial intelligence (AI). Automatic evaluation could improve diagnostic efficiency and help find associations between morphological features and clinical outcome. For development of such prediction models, identifying invasive epithelial cells, and separating these from benign epithelial cells and in situ lesions would be the first step. In this study, we aimed to develop an AI model for segmentation of epithelial cells in sections from breast cancer. We generated epithelial ground truth masks by restaining hematoxylin and eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologistsâ€™ annotations. HE/CK image pairs were used to train a convolutional neural network, and data augmentation was used to make the model more robust. Tissue microarrays (TMAs) from 839 patients, and whole slide images from two patients were used for training and evaluation of the models. The sections were derived from four cohorts of breast cancer patients. TMAs from 21 patients from a fifth cohort was used as a second test set. In quantitative evaluation, a mean Dice score of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial cells, and in situ lesions, respectively, were achieved. In qualitative scoring (0-5) by pathologists, results were best for all epithelium and invasive epithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in situ lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in HE stained breast cancer slides well, but further work is needed for accurate division between the classes. Immunohistochemistry, together with pathologistsâ€™ annotations, enabled the creation of accurate ground truths. The model is made freely available in FastPathology and the code is available at this https://github.com/AICAN-Research/breast-epithelium-segmentation</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hoibo2023immunohistochemistry</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Immunohistochemistry guided segmentation of benign epithelial cells, in situ lesions, and invasive epithelial cells in breast cancer slides}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{HÃ¸ibÃ¸, Maren and Pedersen, AndrÃ© and Dale, Vibeke Grotnes and Berget, Sissel Marie and Ytterhus, Borgny and Lindskog, Cecilia and Wik, Elisabeth and Akslen, Lars A. and Reinertsen, Ingerid and Smistad, Erik and Valla, Marit}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2311.13261}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{eess.IV}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">rgbvalue</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/AICAN-Research/breast-epithelium-segmentation}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2311.13261}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Sci.Rep</abbr></div>

        <!-- Entry bib key -->
        <div id="helland2023postoperative" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Segmentation of glioblastomas in early post-operative multi-modal MRI with deep neural networks</div>
          <!-- Author -->
          <div class="author">Ragnhild Holden Helland,Â Alexandros Ferles,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ivar Kommers,Â Hilko Ardon,Â Frederik Barkhof,Â Lorenzo Bello,Â Mitchel Berger,Â Tora DunÃ¥s,Â Marco Conti Nibali,Â Julia Furtner,Â Shawn Hervey-Jumper,Â Albert Idema,Â Barbara Kiesel,Â Rishi Tewari,Â Emmanuel Mandonnet,Â Domenique MÃ¼ller,Â Pierre Robe,Â Marco Rossi,Â and David Bouget
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Scientific Reports</em> May 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.nature.com/articles/s41598-023-45456-x" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/raidionics/Raidionics" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Extent of resection after surgery is one of the main prognostic factors for patients diagnosed with glioblastoma. To achieve this, accurate segmentation and classification of residual tumor from post-operative MR images is essential. The current standard method for estimating it is subject to high inter- and intra-rater variability, and an automated method for segmentation of residual tumor in early post-operative MRI could lead to a more accurate estimation of extent of resection. In this study, two state-of-the-art neural network architectures for pre-operative segmentation were trained for the task. The models were extensively validated on a multicenter dataset with nearly 1000 patients, from 12 hospitals in Europe and the United States. The best performance achieved was a 61% Dice score, and the best classification performance was about 80% balanced accuracy, with a demonstrated ability to generalize across hospitals. In addition, the segmentation performance of the best models was on par with human expert raters. The predicted segmentations can be used to accurately classify the patients into those with residual tumor, and those with gross total resection.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">helland2023postoperative</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Sci.Rep}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Holden Helland, Ragnhild and Ferles, Alexandros and Pedersen, AndrÃ© and Kommers, Ivar and Ardon, Hilko and Barkhof, Frederik and Bello, Lorenzo and Berger, Mitchel and DunÃ¥s, Tora and Conti Nibali, Marco and Furtner, Julia and Hervey-Jumper, Shawn and Idema, Albert and Kiesel, Barbara and Tewari, Rishi and Mandonnet, Emmanuel and MÃ¼ller, Domenique and Robe, Pierre and Rossi, Marco and Bouget, David}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Segmentation of glioblastomas in early post-operative multi-modal MRI with deep neural networks}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21203/rs.3.rs-2943128/v1}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/raidionics/Raidionics}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.nature.com/articles/s41598-023-45456-x}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Sci.Rep</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2023raidionics" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Raidionics: an open software for pre-and postoperative central nervous system tumor segmentation and standardized reporting</div>
          <!-- Author -->
          <div class="author">David Bouget,Â Demah Alsinan,Â Valeria Gaitan,Â Ragnhild Holden Helland,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ole Solheim,Â and Ingerid Reinertsen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Scientific Reports</em> Sep 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2305.14351.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/raidionics/Raidionics" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=cm9Mxg7Fuj8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>For patients suffering from central nervous system tumors, prognosis estimation, treatment decisions, and postoperative assessments are made from the analysis of a set of magnetic resonance (MR) scans. Currently, the lack of open tools for standardized and automatic tumor segmentation and generation of clinical reports, incorporating relevant tumor characteristics, leads to potential risks from inherent decisionsâ€™ subjectivity. To tackle this problem, the proposed Raidionics open-source software has been developed, offering both a user-friendly graphical user interface and stable processing backend. The software includes preoperative segmentation models for each of the most common tumor types (i.e., glioblastomas, lower grade gliomas, meningiomas, and metastases), together with one early postoperative glioblastoma segmentation model. Preoperative segmentation performances were quite homogeneous across the four different brain tumor types, with an average Dice around 85% and patient-wise recall and precision around 95%. Postoperatively, performances were lower with an average Dice of 41%. Overall, the generation of a standardized clinical report, including the tumor segmentation and features computation, requires about ten minutes on a regular laptop. The proposed Raidionics software is the first open solution enabling an easy use of state-of-the-art segmentation models for all major tumor types, including preoperative and postsurgical standardized reports.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2023raidionics</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Sci.Rep}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Alsinan, Demah and Gaitan, Valeria and Helland, Ragnhild Holden and Pedersen, AndrÃ© and Solheim, Ole and Reinertsen, Ingerid}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Raidionics: an open software for pre-and postoperative central nervous system tumor segmentation and standardized reporting}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41598-023-42048-7}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/raidionics/Raidionics}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2305.14351.pdf}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=cm9Mxg7Fuj8}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PLOS ONE</abbr></div>

        <!-- Entry bib key -->
        <div id="perezdefrutos2022ddmr" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning deep abdominal CT registration through adaptive loss weighting and synthetic data generation</div>
          <!-- Author -->
          <div class="author">Javier Frutos,Â 
                  <em>AndrÃ© Pedersen</em>,Â Egidijus Pelanis,Â David Bouget,Â Shanmugapriya Survarachakan,Â Thomas LangÃ¸,Â Ole-Jakob Elle,Â and Frank Lindseth
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>PLOS ONE</em> Feb 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0282110" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/jpdefrutos/DDMR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Purpose: This study aims to explore training strategies to improve convolutional neural network-based image-to-image deformable registration for abdominal imaging. Methods: Different training strategies, loss functions, and transfer learning schemes were considered. Furthermore, an augmentation layer which generates artificial training image pairs on-the-fly was proposed, in addition to a loss layer that enables dynamic loss weighting. Results: Guiding registration using segmentations in the training step proved beneficial for deep-learning-based image registration. Finetuning the pretrained model from the brain MRI dataset to the abdominal CT dataset further improved performance on the latter application, removing the need for a large dataset to yield satisfactory performance. Dynamic loss weighting also marginally improved performance, all without impacting inference runtime. Conclusion: Using simple concepts, we improved the performance of a commonly used deep image registration architecture, VoxelMorph. In future work, our framework, DDMR, should be validated on different datasets to further assess its value.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">perezdefrutos2022ddmr</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning deep abdominal CT registration through adaptive loss weighting and synthetic data generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{PÃ©rez de Frutos, Javier and Pedersen, AndrÃ© and Pelanis, Egidijus and Bouget, David and Survarachakan, Shanmugapriya and LangÃ¸, Thomas and Elle, Ole-Jakob and Lindseth, Frank}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Public Library of Science}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1371/journal.pone.0282110}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1371/journal.pone.0282110}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/jpdefrutos/DDMR}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0282110}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Fron.Med</abbr></div>

        <!-- Entry bib key -->
        <div id="pedersen2022h2gnet" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">H2G-Net: A multi-resolution refinement approach for segmentation of breast cancer region in gigapixel histopathological images</div>
          <!-- Author -->
          <div class="author">
                  <em>AndrÃ© Pedersen</em>,Â Erik Smistad,Â Tor V. Rise,Â Vibeke G. Dale,Â Henrik S. Pettersen,Â Tor-Arne S. Nordmo,Â David Bouget,Â Ingerid Reinertsen,Â and Marit Valla
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Frontiers in Medicine</em> Sep 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.frontiersin.org/articles/10.3389/fmed.2022.971873/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/andreped/H2G-Net" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://github.com/andreped/H2G-Net/blob/main/poster/poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Over the past decades, histopathological cancer diagnostics has become more complex, and the increasing number of biopsies is a challenge for most pathology laboratories. Thus, development of automatic methods for evaluation of histopathological cancer sections would be of value. In this study, we used 624 whole slide images (WSIs) of breast cancer from a Norwegian cohort. We propose a cascaded convolutional neural network design, called H2G-Net, for segmentation of breast cancer region from gigapixel histopathological images. The design involves a detection stage using a patch-wise method, and a refinement stage using a convolutional autoencoder. To validate the design, we conducted an ablation study to assess the impact of selected components in the pipeline on tumor segmentation. Guiding segmentation, using hierarchical sampling and deep heatmap refinement, proved to be beneficial when segmenting the histopathological images. We found a significant improvement when using a refinement network for post-processing the generated tumor segmentation heatmaps. The overall best design achieved a Dice similarity coefficient of 0.933Â±0.069 on an independent test set of 90 WSIs. The design outperformed single-resolution approaches, such as cluster-guided, patch-wise high-resolution classification using MobileNetV2 (0.872Â±0.092) and a low-resolution U-Net (0.874Â±0.128). In addition, the design performed consistently on WSIs across all histological grades and segmentation on a representative Ã— 400 WSI took Â  58 s, using only the central processing unit. The findings demonstrate the potential of utilizing a refinement network to improve patch-wise predictions. The solution is efficient and does not require overlapping patch inference or ensembling. Furthermore, we showed that deep neural networks can be trained using a random sampling scheme that balances on multiple different labels simultaneously, without the need of storing patches on disk. Future work should involve more efficient patch generation and sampling, as well as improved clustering.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pedersen2022h2gnet</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Fron.Med}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pedersen, AndrÃ© and Smistad, Erik and Rise, Tor V. and Dale, Vibeke G. and Pettersen, Henrik S. and Nordmo, Tor-Arne S. and Bouget, David and Reinertsen, Ingerid and Valla, Marit}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{H2G-Net: A multi-resolution refinement approach for segmentation of breast cancer region in gigapixel histopathological images}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fmed.2022.971873}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fmed.2022.971873}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2296-858X}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/andreped/H2G-Net}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fmed.2022.971873/full}</span><span class="p">,</span>
  <span class="na">poster</span> <span class="p">=</span> <span class="s">{https://github.com/andreped/H2G-Net/blob/main/poster/poster.pdf}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PLOS ONE</abbr></div>

        <!-- Entry bib key -->
        <div id="fredriksen2021teacherstudentlung" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Teacher-student approach for lung tumor segmentation from mixed-supervised datasets</div>
          <!-- Author -->
          <div class="author">Vemund Fredriksen,Â Svein Ole M. Sevle,Â 
                  <em>AndrÃ© Pedersen</em>,Â Thomas LangÃ¸,Â Gabriel Kiss,Â and Frank Lindseth
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>PLOS ONE</em> Apr 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0266147" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/VemundFredriksen/LungTumorMask" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Purpose Cancer is among the leading causes of death in the developed world, and lung cancer is the most lethal type. Early detection is crucial for better prognosis, but can be resource intensive to achieve. Automating tasks such as lung tumor localization and segmentation in radiological images can free valuable time for radiologists and other clinical personnel. Convolutional neural networks may be suited for such tasks, but require substantial amounts of labeled data to train. Obtaining labeled data is a challenge, especially in the medical domain.   Methods This paper investigates the use of a teacher-student design to utilize datasets with different types of supervision to train an automatic model performing pulmonary tumor segmentation on computed tomography images. The framework consists of two models: the student that performs end-to-end automatic tumor segmentation and the teacher that supplies the student additional pseudo-annotated data during training.   Results Using only a small proportion of semantically labeled data and a large number of bounding box annotated data, we achieved competitive performance using a teacher-student design. Models trained on larger amounts of semantic annotations did not perform better than those trained on teacher-annotated data. Our model trained on a small number of semantically labeled data achieved a mean dice similarity coefficient of 71.0 on the MSD Lung dataset.   Conclusions Our results demonstrate the potential of utilizing teacher-student designs to reduce the annotation load, as less supervised annotation schemes may be performed, without any real degradation in segmentation accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fredriksen2021teacherstudentlung</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1371/journal.pone.0266147}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fredriksen, Vemund and Sevle, Svein Ole M. and Pedersen, AndrÃ© and LangÃ¸, Thomas and Kiss, Gabriel and Lindseth, Frank}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{PLOS ONE}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Public Library of Science}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Teacher-student approach for lung tumor segmentation from mixed-supervised datasets}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1371/journal.pone.0266147}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-14}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/VemundFredriksen/LungTumorMask}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0266147}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{13}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Comp.M.Bio</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2021mediastinal" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Mediastinal lymph nodes segmentation using 3D convolutional neural network ensembles and anatomical priors guiding</div>
          <!-- Author -->
          <div class="author">David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Johanna Vanel,Â Haakon O. Leira,Â and Thomas LangÃ¸
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Computer Methods in Biomechanics and Biomedical Engineering: Imaging &amp; Visualization</em> Mar 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.tandfonline.com/doi/full/10.1080/21681163.2022.2043778" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/dbouget/ct_mediastinal_structures_segmentation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>As lung cancer evolves, the presence of potentially malignant lymph nodes must be assessed to properly estimate disease progression and select the best treatment strategy. A method for accurate and automatic segmentation is hence decisive for quantitatively describing lymph nodes. In this study, the use of 3D convolutional neural networks, either through slab-wise schemes or the leveraging of downsampled entire volumes, is investigated. As lymph nodes have similar attenuation values to nearby anatomical structures, we use the knowledge of other organs as prior information to guide the segmentation. To assess the performances, a 5-fold cross-validation strategy was followed over a dataset of 120 contrast-enhanced CT volumes. For the 1178 lymph nodes with a short-axis diameter â‰¥10 mm, our best-performing approach reached a patient-wise recall of 92%, a false positive per patient ratio of 5 and a segmentation overlap of 80.5%. Fusing a slab-wise and a full volume approach within an ensemble scheme generated the best performances. The anatomical priors guiding strategy is promising, yet a larger set than four organs appears needed to generate an optimal benefit. A larger dataset is also mandatory given the wide range of expressions a lymph node can exhibit (i.e. shape, location and attenuation).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2021mediastinal</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Comp.M.Bio}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Pedersen, AndrÃ© and Vanel, Johanna and Leira, Haakon O. and LangÃ¸, Thomas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mediastinal lymph nodes segmentation using 3D convolutional neural network ensembles and anatomical priors guiding}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Methods in Biomechanics and Biomedical Engineering: Imaging \&amp; Visualization}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{0}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{0}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-15}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.tandfonline.com/doi/full/10.1080/21681163.2022.2043778}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/dbouget/ct_mediastinal_structures_segmentation}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Taylor &amp; Francis}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1080/21681163.2022.2043778}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1080/21681163.2022.2043778}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1080/21681163.2022.2043778}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{12}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Book chapter</abbr></div>

        <!-- Entry bib key -->
        <div id="pedersen2022aichapter" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Artificial Intelligence in Studies of Malignant Tumours</div>
          <!-- Author -->
          <div class="author">
                  <em>AndrÃ© Pedersen</em>,Â Ingerid Reinertsen,Â Emiel Janssen,Â and Marit Valla
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In book: Biomarkers of the Tumor Microenvironment</em> Jan 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>With the introduction of digital pathology and artificial intelligence (AI)-based methods, we may be facing a new era in cancer diagnostics and prognostication. AI can assist pathologists in labour-intensive tasks and potentially discover new features currently not detected and characterized in routine diagnostics. As entire digital histopathological sections can be included in the analysis, AI can be used both to study the epithelial component of a tumour and the microenvironment. Most state-of-the-art AI approaches used for image analysis utilize multi-step pipelines. AI-based methods have shown promising results in a wide range of clinically relevant tasks. It is, however, important to be aware of some challenges and limitations, such as the lack of generalizability of AI-based models, and the importance of understanding the reason behind a conclusion.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pedersen2022aichapter</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Book chapter}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pedersen, AndrÃ© and Reinertsen, Ingerid and Janssen, Emiel and Valla, Marit}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{365--375}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial Intelligence in Studies of Malignant Tumours}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{In book: Biomarkers of the Tumor Microenvironment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Biomarkers of the Tumor Microenvironment}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-98949-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{doi.org/10.1007/978-3-030-98950-7_21}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-98950-7_21}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Fron.Neu</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2022preoperative" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Preoperative Brain Tumor Imaging: Models and Software for Segmentation and Standardized Reporting</div>
          <!-- Author -->
          <div class="author">David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Asgeir S. Jakola,Â Vasileios Kavouridis,Â Kyrre E. Emblem,Â Roelant S. Eijgelaar,Â Ivar Kommers,Â Hilko Ardon,Â Frederik Barkhof,Â Lorenzo Bello,Â Mitchel S. Berger,Â Marco Conti Nibali,Â Julia Furtner,Â Shawn Hervey-Jumper,Â Albert J. S. Idema,Â Barbara Kiesel,Â Alfred Kloet,Â Emmanuel Mandonnet,Â Domenique M. J. MÃ¼ller,Â Pierre A. Robe,Â Marco Rossi,Â Tommaso Sciortino,Â Wimar A. Brink,Â Michiel Wagemakers,Â Georg Widhalm,Â Marnix G. Witte,Â Aeilko H. Zwinderman,Â Philip C. De Witt Hamer,Â Ole Solheim,Â and Ingerid Reinertsen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Frontiers in Neurology</em> Jan 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.frontiersin.org/articles/10.3389/fneur.2022.932219/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/dbouget/Raidionics" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>For patients suffering from brain tumor, prognosis estimation and treatment decisions are made by a multidisciplinary team based on a set of preoperative MR scans. Currently, the lack of standardized and automatic methods for tumor detection and generation of clinical reports, incorporating a wide range of tumor characteristics, represents a major hurdle. In this study, we investigate the most occurring brain tumor types: glioblastomas, lower grade gliomas, meningiomas, and metastases, through four cohorts of up to 4,000 patients. Tumor segmentation models were trained using the AGU-Net architecture with different preprocessing steps and protocols. Segmentation performances were assessed in-depth using a wide-range of voxel and patient-wise metrics covering volume, distance, and probabilistic aspects. Finally, two software solutions have been developed, enabling an easy use of the trained models and standardized generation of clinical reports: Raidionics and Raidionics-Slicer. Segmentation performances were quite homogeneous across the four different brain tumor types, with an average true positive Dice ranging between 80 and 90%, patient-wise recall between 88 and 98%, and patient-wise precision around 95%. In conjunction to Dice, the identified most relevant other metrics were the relative absolute volume difference, the variation of information, and the Hausdorff, Mahalanobis, and object average symmetric surface distances. With our Raidionics software, running on a desktop computer with CPU support, tumor segmentation can be performed in 16â€“54 s depending on the dimensions of the MRI volume. For the generation of a standardized clinical report, including the tumor segmentation and features computation, 5â€“15 min are necessary. All trained models have been made open-access together with the source code for both software solutions and validation metrics computation. In the future, a method to convert results from a set of metrics into a final single score would be highly desirable for easier ranking across trained models. In addition, an automatic classification of the brain tumor type would be necessary to replace manual user input. Finally, the inclusion of post-operative segmentation in both software solutions will be key for generating complete post-operative standardized clinical reports.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2022preoperative</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Fron.Neu}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Pedersen, AndrÃ© and Jakola, Asgeir S. and Kavouridis, Vasileios and Emblem, Kyrre E. and Eijgelaar, Roelant S. and Kommers, Ivar and Ardon, Hilko and Barkhof, Frederik and Bello, Lorenzo and Berger, Mitchel S. and Conti Nibali, Marco and Furtner, Julia and Hervey-Jumper, Shawn and Idema, Albert J. S. and Kiesel, Barbara and Kloet, Alfred and Mandonnet, Emmanuel and MÃ¼ller, Domenique M. J. and Robe, Pierre A. and Rossi, Marco and Sciortino, Tommaso and Van den Brink, Wimar A. and Wagemakers, Michiel and Widhalm, Georg and Witte, Marnix G. and Zwinderman, Aeilko H. and De Witt Hamer, Philip C. and Solheim, Ole and Reinertsen, Ingerid}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Preoperative Brain Tumor Imaging: Models and Software for Segmentation and Standardized Reporting}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neurology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fneur.2022.932219}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fneur.2022.932219}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1664-2295}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/dbouget/Raidionics}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fneur.2022.932219/full}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Fron.Med</abbr></div>

        <!-- Entry bib key -->
        <div id="pettersen2021codefree" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Code-Free Development and Deployment of Deep Segmentation Models for Digital Pathology</div>
          <!-- Author -->
          <div class="author">Henrik S. Pettersen,Â Ilya Belevich,Â Elin S. RÃ¸yset,Â Melanie R. Simpson,Â Erik Smistad,Â Eija Jokitalo,Â Ingerid Reinertsen,Â Ingunn Bakke,Â and <em>AndrÃ© Pedersen</em>
                
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Frontiers in Medicine</em> Jan 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.frontiersin.org/articles/10.3389/fmed.2021.816281/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/andreped/NoCodeSeg" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=9dTfUwnL6zY" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Application of deep learning on histopathological whole slide images (WSIs) holds promise of improving diagnostic efficiency and reproducibility but is largely dependent on the ability to write computer code or purchase commercial solutions. We present a code-free pipeline utilizing free-to-use, open-source software (QuPath, DeepMIB, and FastPathology) for creating and deploying deep learning-based segmentation models for computational pathology. We demonstrate the pipeline on a use case of separating epithelium from stroma in colonic mucosa. A dataset of 251 annotated WSIs, comprising 140 hematoxylin-eosin (HE)-stained and 111 CD3 immunostained colon biopsy WSIs, were developed through active learning using the pipeline. On a hold-out test set of 36 HE and 21 CD3-stained WSIs a mean intersection over union score of 95.5 and 95.3% was achieved on epithelium segmentation. We demonstrate pathologist-level segmentation accuracy and clinical acceptable runtime performance and show that pathologists without programming experience can create near state-of-the-art segmentation solutions for histopathological WSIs using only free-to-use software. The study further demonstrates the strength of open-source solutions in its ability to create generalizable, open pipelines, of which trained models and predictions can seamlessly be exported in open formats and thereby used in external solutions. All scripts, trained models, a video tutorial, and the full dataset of 251 WSIs with Â 31 k epithelium annotations are made openly available at https://github.com/andreped/NoCodeSeg to accelerate research in the field.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pettersen2021codefree</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Fron.Med}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Code-Free Development and Deployment of Deep Segmentation Models for Digital Pathology}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pettersen, Henrik S. and Belevich, Ilya and RÃ¸yset, Elin S. and Simpson, Melanie R. and Smistad, Erik and Jokitalo, Eija and Reinertsen, Ingerid and Bakke, Ingunn and Pedersen, AndrÃ©}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/article/10.3389/fmed.2021.816281}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2296-858X}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fmed.2021.816281/full}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/andreped/NoCodeSeg}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=9dTfUwnL6zY}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://dataverse.no/dataset.xhtml?persistentId=doi:10.18710/TLA01U}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{8}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IEEE-B</abbr></div>

        <!-- Entry bib key -->
        <div id="yan2021sepsis" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Preliminary Processing and Analysis of an Adverse Event Dataset for Detecting Sepsis-Related Events</div>
          <!-- Author -->
          <div class="author">Melissa Yan,Â Lise Husby HÃ¸vik,Â 
                  <em>AndrÃ© Pedersen</em>,Â Lise Tuset Gustad,Â and Ã˜ystein NytrÃ¸
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>2021 IEEE International Conference on Bioinformatics and Biomedicine</em> Dec 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://github.com/andreped/adverse-events" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Adverse event (AE) reports contain notes detailing procedural and guideline deviations, and unwanted incidents that can bring harm to patients. Available datasets mainly focus on vigilance or post-market surveillance of adverse drug reactions or
medical device failures. The lack of clinical-related AE datasets makes it challenging to study healthcare-related AEs. AEs affect 10% of hospitalized patients, and almost half are preventable. Having an AE dataset can assist in identifying possible patient
safety interventions and performing quality surveillance to lower AE rates. The free-text notes can provide insight into the cause of incidents and lead to better patient care. The objective of this study is to introduce a Norwegian AE dataset and present preliminary processing and analysis for sepsis-related events, specifically peripheral intravenous catheter-related bloodstream infections. Therefore, the methods focus on performing a domain analysis to prepare and better understand the data through screening, generating synthetic free-text notes, and annotating
notes.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yan2021sepsis</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IEEE-B}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Preliminary Processing and Analysis of an Adverse Event Dataset for Detecting Sepsis-Related Events}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Melissa and HÃ¸vik, Lise Husby and Pedersen, AndrÃ© and Gustad, Lise Tuset and NytrÃ¸, Ã˜ystein}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{2021 IEEE International Conference on Bioinformatics and Biomedicine}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/andreped/adverse-events}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{9}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Cancers</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2021glioma" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Glioblastoma Surgery Imaging-Reporting and Data System: Validation and Performance of the Automated Segmentation Task</div>
          <!-- Author -->
          <div class="author">David Bouget,Â Roelant Eijgelaar,Â 
                  <em>AndrÃ© Pedersen</em>,Â Ivar Kommers,Â Hilko Ardon,Â Frederik Barkhof,Â Lorenzo Bello,Â Mitchel Berger,Â Marco Conti Nibali,Â Julia Furtner,Â Even Fyllingen,Â Shawn Hervey-Jumper,Â Albert Idema,Â Barbara Kiesel,Â Alfred Kloet,Â Emmanuel Mandonnet,Â Domenique MÃ¼ller,Â Pierre Robe,Â Marco Rossi,Â and Ole Solheim
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Cancers</em> Sep 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.mdpi.com/2072-6694/13/18/4674/htm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/SINTEFMedtek/GSI-RADS" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>For patients with presumed glioblastoma, essential tumor characteristics are determined from preoperative MR images to optimize the treatment strategy. This procedure is time-consuming and subjective, if performed by crude eyeballing or manually. The standardized GSI-RADS aims to provide neurosurgeons with automatic tumor segmentations to extract tumor features rapidly and objectively. In this study, we improved automatic tumor segmentation and compared the agreement with manual raters, describe the technical details of the different components of GSI-RADS, and determined their speed. Two recent neural network architectures were considered for the segmentation task: nnU-Net and AGU-Net. Two preprocessing schemes were introduced to investigate the tradeoff between performance and processing speed. A summarized description of the tumor feature extraction and standardized reporting process is included. The trained architectures for automatic segmentation and the code for computing the standardized report are distributed as open-source and as open-access software. Validation studies were performed on a dataset of 1594 gadolinium-enhanced T1-weighted MRI volumes from 13 hospitals and 293 T1-weighted MRI volumes from the BraTS challenge. The glioblastoma tumor core segmentation reached a Dice score slightly below 90%, a patientwise F1-score close to 99%, and a 95th percentile Hausdorff distance slightly below 4.0 mm on average with either architecture and the heavy preprocessing scheme. A patient MRI volume can be segmented in less than one minute, and a standardized report can be generated in up to five minutes. The proposed GSI-RADS software showed robust performance on a large collection of MRI volumes from various hospitals and generated results within a reasonable runtime.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2021glioma</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Cancers}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Eijgelaar, Roelant and Pedersen, AndrÃ© and Kommers, Ivar and Ardon, Hilko and Barkhof, Frederik and Bello, Lorenzo and Berger, Mitchel and Conti Nibali, Marco and Furtner, Julia and Fyllingen, Even and Hervey-Jumper, Shawn and Idema, Albert and Kiesel, Barbara and Kloet, Alfred and Mandonnet, Emmanuel and MÃ¼ller, Domenique and Robe, Pierre and Rossi, Marco and Solheim, Ole}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Glioblastoma Surgery Imaging-Reporting and Data System: Validation and Performance of the Automated Segmentation Task}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Cancers}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/cancers13184674}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-6694/13/18/4674/htm}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/SINTEFMedtek/GSI-RADS}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{7}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Fron.Rad</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2021attention" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Meningioma Segmentation in T1-Weighted MRI Leveraging Global Context and Attention Mechanisms</div>
          <!-- Author -->
          <div class="author">David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Sayied Hosainey,Â Ole Solheim,Â and Ingerid Reinertsen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Frontiers in Radiology</em> Sep 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.frontiersin.org/articles/10.3389/fradi.2021.711514/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/dbouget/mri_brain_tumor_segmentation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Purpose: Meningiomas are the most common type of primary brain tumor, accounting for Â 30% of all brain tumors. A substantial number of these tumors are never surgically removed but rather monitored over time. Automatic and precise meningioma segmentation is, therefore, beneficial to enable reliable growth estimation and patient-specific treatment planning. Methods: In this study, we propose the inclusion of attention mechanisms on top of a U-Net architecture used as backbone: (i) Attention-gated U-Net (AGUNet) and (ii) Dual Attention U-Net (DAUNet), using a three-dimensional (3D) magnetic resonance imaging (MRI) volume as input. Attention has the potential to leverage the global context and identify featuresâ€™ relationships across the entire volume. To limit spatial resolution degradation and loss of detail inherent to encoderâ€“decoder architectures, we studied the impact of multi-scale input and deep supervision components. The proposed architectures are trainable end-to-end and each concept can be seamlessly disabled for ablation studies. Results: The validation studies were performed using a five-fold cross-validation over 600 T1-weighted MRI volumes from St. Olavs Hospital, Trondheim University Hospital, Norway. Models were evaluated based on segmentation, detection, and speed performances, and results are reported patient-wise after averaging across all folds. For the best-performing architecture, an average Dice score of 81.6% was reached for an F1-score of 95.6%. With an almost perfect precision of 98%, meningiomas smaller than 3 ml were occasionally missed hence reaching an overall recall of 93%. Conclusion: Leveraging global context from a 3D MRI volume provided the best performances, even if the native volume resolution could not be processed directly due to current GPU memory limitations. Overall, near-perfect detection was achieved for meningiomas larger than 3 ml, which is relevant for clinical use. In the future, the use of multi-scale designs and refinement networks should be further investigated. A larger number of cases with meningiomas below 3 ml might also be needed to improve the performance for the smallest tumors.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2021attention</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Fron.Rad}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Pedersen, AndrÃ© and Hosainey, Sayied and Solheim, Ole and Reinertsen, Ingerid}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{711514}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Meningioma Segmentation in T1-Weighted MRI Leveraging Global Context and Attention Mechanisms}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Radiology}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fradi.2021.711514}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/articles/10.3389/fradi.2021.711514/full}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/dbouget/mri_brain_tumor_segmentation}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{6}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Cancers</abbr></div>

        <!-- Entry bib key -->
        <div id="kommers2021gsirads" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Glioblastoma Surgery Imagingâ€”Reporting and Data System: Standardized Reporting of Tumor Volume, Location, and Resectability Based on Automated Segmentations</div>
          <!-- Author -->
          <div class="author">Ivar Kommers,Â David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Roelant Eijgelaar,Â Hilko Ardon,Â Frederik Barkhof,Â Lorenzo Bello,Â Mitchel Berger,Â Marco Conti Nibali,Â Julia Furtner,Â Even Fyllingen,Â Shawn Hervey-Jumper,Â Albert Idema,Â Barbara Kiesel,Â Alfred Kloet,Â Emmanuel Mandonnet,Â Domenique MÃ¼ller,Â Pierre Robe,Â Marco Rossi,Â and Philip De Witt Hamer
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Cancers</em> Jun 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.mdpi.com/2072-6694/13/12/2854/htm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/SINTEFMedtek/GSI-RADS" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Treatment decisions for patients with presumed glioblastoma are based on tumor characteristics available from a preoperative MR scan. Tumor characteristics, including volume, location, and resectability, are often estimated or manually delineated. This process is time consuming and subjective. Hence, comparison across cohorts, trials, or registries are subject to assessment bias. In this study, we propose a standardized Glioblastoma Surgery Imaging Reporting and Data System (GSI-RADS) based on an automated method of tumor segmentation that provides standard reports on tumor features that are potentially relevant for glioblastoma surgery. As clinical validation, we determine the agreement in extracted tumor features between the automated method and the current standard of manual segmentations from routine clinical MR scans before treatment. In an observational consecutive cohort of 1596 adult patients with a first time surgery of a glioblastoma from 13 institutions, we segmented gadolinium-enhanced tumor parts both by a human rater and by an automated algorithm. Tumor features were extracted from segmentations of both methods and compared to assess differences, concordance, and equivalence. The laterality, contralateral infiltration, and the laterality indices were in excellent agreement. The native and normalized tumor volumes had excellent agreement, consistency, and equivalence. Multifocality, but not the number of foci, had good agreement and equivalence. The location profiles of cortical and subcortical structures were in excellent agreement. The expected residual tumor volumes and resectability indices had excellent agreement, consistency, and equivalence. Tumor probability maps were in good agreement. In conclusion, automated segmentations are in excellent agreement with manual segmentations and practically equivalent regarding tumor features that are potentially relevant for neurosurgical purposes. Standard GSI-RADS reports can be generated by open access software.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">kommers2021gsirads</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Cancers}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kommers, Ivar and Bouget, David and Pedersen, AndrÃ© and Eijgelaar, Roelant and Ardon, Hilko and Barkhof, Frederik and Bello, Lorenzo and Berger, Mitchel and Conti Nibali, Marco and Furtner, Julia and Fyllingen, Even and Hervey-Jumper, Shawn and Idema, Albert and Kiesel, Barbara and Kloet, Alfred and Mandonnet, Emmanuel and MÃ¼ller, Domenique and Robe, Pierre and Rossi, Marco and De Witt Hamer, Philip}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2854}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Glioblastoma Surgery Imagingâ€”Reporting and Data System: Standardized Reporting of Tumor Volume, Location, and Resectability Based on Automated Segmentations}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Cancers}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/cancers13122854}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2072-6694/13/12/2854/htm}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/SINTEFMedtek/GSI-RADS}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{5}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IEEE-A</abbr></div>

        <!-- Entry bib key -->
        <div id="pedersen2021fastpathology" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">FastPathology: An Open-Source Platform for Deep Learning-Based Research and Decision Support in Digital Pathology</div>
          <!-- Author -->
          <div class="author">
                  <em>AndrÃ© Pedersen</em>,Â Marit Valla,Â Anna Bofin,Â Javier Frutos,Â Ingerid Reinertsen,Â and Erik Smistad
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Access</em> Apr 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9399433" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/AICAN-Research/FAST-Pathology" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=1s7jU6T7S3U" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep convolutional neural networks (CNNs) are the current state-of-the-art for digital analysis of histopathological images. The large size of whole-slide microscopy images (WSIs) requires advanced memory handling to read, display and process these images. There are several open-source platforms for working with WSIs, but few support deployment of CNN models. These applications use third-party solutions for inference, making them less user-friendly and unsuitable for high-performance image analysis. To make deployment of CNNs user-friendly and feasible on low-end machines, we have developed a new platform, FastPathology, using the FAST framework and C++. It minimizes memory usage for reading and processing WSIs, deployment of CNN models, and real-time interactive visualization of results. Runtime experiments were conducted on four different use cases, using different architectures, inference engines, hardware configurations and operating systems. Memory usage for reading, visualizing, zooming and panning a WSI were measured, using FastPathology and three existing platforms. FastPathology performed similarly in terms of memory to the other C++-based application, while using considerably less than the two Java-based platforms. The choice of neural network model, inference engine, hardware and processors influenced runtime considerably. Thus, FastPathology includes all steps needed for efficient visualization and processing of WSIs in a single application, including inference of CNNs with real-time display of the results. Source code, binary releases, video demonstrations and test data can be found online on GitHub at https://github.com/SINTEFMedtek/FAST-Pathology/.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pedersen2021fastpathology</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IEEE-A}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pedersen, AndrÃ© and Valla, Marit and Bofin, Anna and PÃ©rez de Frutos, Javier and Reinertsen, Ingerid and Smistad, Erik}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-1}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FastPathology: An Open-Source Platform for Deep Learning-Based Research and Decision Support in Digital Pathology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{PP}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2021.3072231}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9399433}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/AICAN-Research/FAST-Pathology}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=1s7jU6T7S3U}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{4}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">JMI</abbr></div>

        <!-- Entry bib key -->
        <div id="bouget2021meningioma" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Fast meningioma segmentation in T1-weighted magnetic resonance imaging volumes using a lightweight 3D deep learning architecture</div>
          <!-- Author -->
          <div class="author">David Bouget,Â 
                  <em>AndrÃ© Pedersen</em>,Â Sayied Hosainey,Â Johanna Vanel,Â Ole Solheim,Â and Ingerid Reinertsen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Medical Imaging</em> Mar 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2010.07002.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Purpose: Automatic and consistent meningioma segmentation in T1-weighted magnetic resonance (MR) imaging volumes and corresponding volumetric assessment is of use for diagnosis, treatment planning, and tumor growth evaluation. We optimized the segmentation and processing speed performances using a large number of both surgically treated meningiomas and untreated meningiomas followed at the outpatient clinic. Approach: We studied two different three-dimensional (3D) neural network architectures: (i) a simple encoder-decoder similar to a 3D U-Net, and (ii) a lightweight multi-scale architecture [Pulmonary Lobe Segmentation Network (PLS-Net)]. In addition, we studied the impact of different training schemes. For the validation studies, we used 698 T1-weighted MR volumes from St. Olav University Hospital, Trondheim, Norway. The models were evaluated in terms of detection accuracy, segmentation accuracy, and training/inference speed. Results: While both architectures reached a similar Dice score of 70% on average, the PLS-Net was more accurate with an F1-score of up to 88%. The highest accuracy was achieved for the largest meningiomas. Speed-wise, the PLS-Net architecture tended to converge in about 50 h while 130 h were necessary for U-Net. Inference with PLS-Net takes less than a second on GPU and about 15 s on CPU. Conclusions: Overall, with the use of mixed precision training, it was possible to train competitive segmentation models in a relatively short amount of time using the lightweight PLS-Net architecture. In the future, the focus should be brought toward the segmentation of small meningiomas (&lt;2 ml) to improve clinical relevance for automatic and early diagnosis and speed of growth estimates.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bouget2021meningioma</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{JMI}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bouget, David and Pedersen, AndrÃ© and Hosainey, Sayied and Vanel, Johanna and Solheim, Ole and Reinertsen, Ingerid}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-16}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast meningioma segmentation in T1-weighted magnetic resonance imaging volumes using a lightweight 3D deep learning architecture}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Medical Imaging}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1117/1.JMI.8.2.024002}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2010.07002.pdf}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{3}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">UMB</abbr></div>

        <!-- Entry bib key -->
        <div id="Snipstad2021bubblecan" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sonopermeation Enhances Uptake and Therapeutic Effect of Free and Encapsulated Cabazitaxel</div>
          <!-- Author -->
          <div class="author">Sofie Snipstad,Â Yrr MÃ¸rch,Â Einar Sulheim,Â Andreas Aslund,Â Catharina Davies,Â Rune Hansen,Â Sigrid Berg,Â and <em>AndrÃ© Pedersen</em>
                
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Ultrasound in Medicine &amp; Biology</em> Feb 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.umbjournal.org/article/S0301-5629(21)00004-1/fulltext" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Delivery of drugs and nanomedicines to tumors is often heterogeneous and insufficient and, thus, of limited efficacy. Microbubbles in combination with ultrasound have been found to improve delivery to tumors, enhancing accumulation and penetration. We used a subcutaneous prostate cancer xenograft model in mice to investigate the effect of free and nanoparticle-encapsulated cabazitaxel in combination with ultrasound and microbubbles with a lipid shell or a shell of nanoparticles. Sonopermeation reduced tumor growth and prolonged survival (26%-100%), whether the free drug was co-injected with lipid-shelled microbubbles or the nanoformulation was co-injected with lipid-shelled or nanoparticle-shelled microbubbles. Coherently with the improved therapeutic response, we found enhanced uptake of nanoparticles directly after ultrasound treatment that lasted several weeks (2.3x-15.8x increase). Neither cavitation dose nor total accumulation of nanoparticles could explain the variation within treatment groups, emphasizing the need for a better understanding of the tumor biology and mechanisms involved in ultrasound-mediated treatment.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Snipstad2021bubblecan</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{UMB}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Snipstad, Sofie and MÃ¸rch, Yrr and Sulheim, Einar and Aslund, Andreas and Davies, Catharina and Hansen, Rune and Berg, Sigrid and Pedersen, AndrÃ©}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sonopermeation Enhances Uptake and Therapeutic Effect of Free and Encapsulated Cabazitaxel}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{47}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Ultrasound in Medicine &amp; Biology}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.ultrasmedbio.2020.12.026}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.umbjournal.org/article/S0301-5629(21)00004-1/fulltext}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{2}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IEEE-A</abbr></div>

        <!-- Entry bib key -->
        <div id="smistad2019fast" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">High Performance Neural Network Inference, Streaming, and Visualization of Medical Images Using FAST</div>
          <!-- Author -->
          <div class="author">Erik Smistad,Â Andreas Ã˜stvik,Â and <em>AndrÃ© Pedersen</em>
                
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Access</em> Sep 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8844665" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/smistad/FAST" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=iuevRnZMDgg" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep convolutional neural networks have quickly become the standard for medical image analysis. Although there are many frameworks focusing on training neural networks, there are few that focus on high performance inference and visualization of medical images. Neural network inference requires an inference engine (IE), and there are currently several IEs available including Intelâ€™s OpenVINO, NVIDIAâ€™s TensorRT, and Googleâ€™s TensorFlow which supports multiple backends, including NVIDIAâ€™s cuDNN, AMDâ€™s ROCm and Intelâ€™s MKL-DNN. These IEs only work on specific processors and have completely different application programming interfaces (APIs). In this paper, we presents methods for extending FAST, an open-source high performance framework for medical imaging, to use any IE with a common programming interface. Thereby making it easier for users to deploy and test their neural networks on different processors. This article provides an overview of current IEs and how they can be combined with existing software such as FAST. The methods are demonstrated and evaluated on three performance demanding medical use cases: real-time ultrasound image segmentation, computed tomography (CT) volume segmentation, and patch-wise classification of whole slide microscopy images. Runtime performance was measured on the three use cases with several different IEs and processors. This revealed that the choice of IE and processor can affect performance of medical neural network image analysis considerably. In the most extreme case of processing 171 ultrasound frames, the difference between the fastest and slowest configuration were half a second vs. 24 seconds. For volume processing, using the CPU or the GPU, showed a difference of 2 vs. 53 seconds, and for processing an whole slide microscopy image, the difference was 81 seconds vs. almost 16 minutes. Source code, binary releases and test data can be found online on GitHub at https://github.com/smistad/FAST/.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">smistad2019fast</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IEEE-A}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Smistad, Erik and Ã˜stvik, Andreas and Pedersen, AndrÃ©}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-1}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High Performance Neural Network Inference, Streaming, and Visualization of Medical Images Using FAST}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{PP}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2019.2942441}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8844665}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/smistad/FAST}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=iuevRnZMDgg}</span><span class="p">,</span>
  <span class="na">rgvalue</span> <span class="p">=</span> <span class="s">{1}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2025 AndrÃ©  Pedersen. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>
  </body>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  <!-- Mansory & imagesLoaded -->
  <script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  <script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
  
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
</html>

